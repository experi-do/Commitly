"""
ReviewAgent êµ¬í˜„

LLMì„ ì‚¬ìš©í•œ ì½”ë“œ ë¦¬ë·°
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from commitly.agents.base import BaseAgent
from commitly.core.context import RunContext, AgentOutput
from commitly.core.git_manager import GitManager


class ReviewAgent(BaseAgent):
    """
    Review Agent

    ì—­í• :
    1. commitly/review/{pipeline_id} ë¸Œëœì¹˜ ìƒì„±
    2. ì‚¬ìš©ì ì›ë³¸ ë³€ê²½ì‚¬í•­(git diff) ì¶”ì¶œ
    3. LLMì„ í†µí•œ ì½”ë“œ ë¦¬ë·° ìˆ˜í–‰
    4. CRITICAL/HIGH ì´ìŠˆ ë°œê²¬ ì‹œ ìŠ¹ì¸ ê²Œì´íŠ¸
    5. ë¦¬ë·° ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ì €ì¥
    """

    def __init__(self, run_context: RunContext) -> None:
        super().__init__(run_context)

        self.hub_path = self._get_hub_path()
        self.hub_git = GitManager(self.hub_path, self.logger)

    def run(self) -> AgentOutput:
        """
        ReviewAgent ì‹¤í–‰ ë° SyncAgent í˜¸í™˜ ìºì‹œ ìƒì„±

        BaseAgent.run()ì„ í˜¸ì¶œí•˜ê³ , ì¶”ê°€ë¡œ refactoring_agent.jsonì„ ìƒì„±í•©ë‹ˆë‹¤.
        (ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ê³¼ì˜ í˜¸í™˜ì„± ìœ ì§€)
        """
        # BaseAgentì˜ run() ë©”ì„œë“œ í˜¸ì¶œ
        output = super().run()

        # SyncAgent í˜¸í™˜ì„±: refactoring_agent.jsonë„ ìƒì„±
        if output["status"] == "success":
            self._save_compatibility_cache(output)

        return output

    def _save_compatibility_cache(self, output: AgentOutput) -> None:
        """
        SyncAgent í˜¸í™˜ì„±ì„ ìœ„í•´ refactoring_agent.json ìƒì„±

        ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ì—ì„œ RefactoringAgentì˜ ì¶œë ¥ì„ ê¸°ëŒ€í•˜ëŠ” SyncAgentì™€
        í˜¸í™˜ë˜ë„ë¡ refactoring_agent.jsonì„ ìƒì„±í•©ë‹ˆë‹¤.
        """
        try:
            # í˜¸í™˜ ìºì‹œ ë°ì´í„° ìƒì„±
            # SyncAgentì˜ _collect_agent_results()ê°€ ê¸°ëŒ€í•˜ëŠ” êµ¬ì¡°
            compat_output = {
                "pipeline_id": self.run_context["pipeline_id"],
                "agent_name": "refactoring_agent",  # SyncAgentê°€ ì´ ì´ë¦„ìœ¼ë¡œ ì¡°íšŒ
                "agent_branch": self.run_context.get("review_agent_branch", ""),
                "status": "success",
                "started_at": output["started_at"],
                "ended_at": output["ended_at"],
                "error": None,
                "data": {
                    # SyncAgentì˜ _collect_agent_results()ê°€ ê¸°ëŒ€í•˜ëŠ” êµ¬ì¡°
                    "refactoring_summary": {
                        "refactored_files_count": 0,  # ReviewëŠ” ì½”ë“œ ìˆ˜ì • ì•ˆ í•¨
                        "total_files_checked": 0,
                        "details": [],
                    }
                },
            }

            # ìºì‹œ ë””ë ‰í† ë¦¬
            cache_dir = self.run_context["workspace_path"] / ".commitly" / "cache"
            cache_dir.mkdir(parents=True, exist_ok=True)

            # refactoring_agent.jsonì— ì €ì¥
            cache_file = cache_dir / "refactoring_agent.json"
            with open(cache_file, "w", encoding="utf-8") as f:
                json.dump(compat_output, f, indent=2, ensure_ascii=False)

            self.logger.debug(f"í˜¸í™˜ ìºì‹œ ì €ì¥: {cache_file}")

        except Exception as e:
            self.logger.warning(f"í˜¸í™˜ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            # í˜¸í™˜ ìºì‹œ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì  ì˜¤ë¥˜ ì•„ë‹˜

    def execute(self) -> Dict[str, Any]:
        """
        Review Agent ì‹¤í–‰

        Returns:
            {
                "overall_assessment": str,  # APPROVE | REQUEST_CHANGES | COMMENT
                "issues": List[Dict],  # ë°œê²¬ëœ ì´ìŠˆ ëª©ë¡
                "issue_count": Dict,  # ì‹¬ê°ë„ë³„ ì¹´ìš´íŠ¸
                "positive_aspects": List[str],  # ê¸ì •ì  ì¸¡ë©´
                "user_approved": bool,  # ì‚¬ìš©ì ìŠ¹ì¸ ì—¬ë¶€
            }
        """
        # 1. ë¸Œëœì¹˜ ìƒì„±
        self._create_agent_branch()

        # 2. git diff ì¶”ì¶œ (ì‚¬ìš©ì ì›ë³¸ ë³€ê²½ì‚¬í•­)
        diff_content = self._get_user_changes_diff()

        if not diff_content or diff_content.strip() == "":
            self.logger.info("ë³€ê²½ì‚¬í•­ ì—†ìŒ, ë¦¬ë·° ìŠ¤í‚µ")
            return {
                "overall_assessment": "APPROVE",
                "issues": [],
                "issue_count": {"critical": 0, "high": 0, "medium": 0, "low": 0},
                "positive_aspects": ["ë³€ê²½ì‚¬í•­ ì—†ìŒ"],
                "user_approved": True,
            }

        # 3. LLM ë¦¬ë·° ìˆ˜í–‰
        review_result = self._perform_llm_review(diff_content)

        # 4. ìŠ¹ì¸ ê²Œì´íŠ¸ (CRITICAL/HIGH ì´ìŠˆê°€ ìˆì„ ë•Œë§Œ)
        user_approved = self._approval_gate(review_result)

        if not user_approved:
            raise RuntimeError(
                "ì‚¬ìš©ìê°€ ì½”ë“œ ë¦¬ë·° ê²°ê³¼ë¥¼ í™•ì¸í•œ í›„ ì§„í–‰ì„ ê±°ë¶€í–ˆìŠµë‹ˆë‹¤.\n"
                "ì´ìŠˆë¥¼ ìˆ˜ì •í•œ í›„ ë‹¤ì‹œ ì»¤ë°‹í•´ì£¼ì„¸ìš”."
            )

        # 5. ê²°ê³¼ ë°˜í™˜
        return {
            "overall_assessment": review_result["overall_assessment"],
            "issues": review_result["issues"],
            "issue_count": review_result["issue_count"],
            "positive_aspects": review_result.get("positive_aspects", []),
            "user_approved": user_approved,
        }

    def _create_agent_branch(self) -> None:
        """ì—ì´ì „íŠ¸ ë¸Œëœì¹˜ ìƒì„±"""
        pipeline_id = self.run_context["pipeline_id"]
        branch_name = f"commitly/review/{pipeline_id}"

        # ë¶€ëª¨ ë¸Œëœì¹˜: Test Agent ë¸Œëœì¹˜
        parent_branch = self.run_context["test_agent_branch"]

        self.hub_git.create_branch(branch_name, parent_branch)

        self.agent_branch = branch_name
        self.run_context["review_agent_branch"] = branch_name

        # SyncAgent í˜¸í™˜ì„±ì„ ìœ„í•´ refactoring_agent_branchë„ ì„¤ì •
        # (ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ì—ì„œ RefactoringAgent â†’ ReviewAgentë¡œ ë³€ê²½)
        self.run_context["refactoring_agent_branch"] = branch_name

        self.logger.info(f"ì—ì´ì „íŠ¸ ë¸Œëœì¹˜ ìƒì„±: {branch_name}")

    def _get_user_changes_diff(self) -> str:
        """
        ì‚¬ìš©ì ì›ë³¸ ë³€ê²½ì‚¬í•­ ì¶”ì¶œ

        CloneAgentê°€ ì»¤ë°‹í•œ ë³€ê²½ì‚¬í•­ë§Œ ê°€ì ¸ì˜´ (RefactoringAgent ìˆ˜ì • ì œì™¸)

        Returns:
            git diff ê²°ê³¼ ë¬¸ìì—´
        """
        # Clone Agentì˜ ì»¤ë°‹ë§Œ diffë¡œ ê°€ì ¸ì˜¤ê¸°
        # Test Agent ë¸Œëœì¹˜ ê¸°ì¤€ìœ¼ë¡œ mainê³¼ ë¹„êµ
        try:
            # main ë¸Œëœì¹˜ì™€ í˜„ì¬ ë¸Œëœì¹˜ì˜ diff
            diff_result = self.hub_git.repo.git.diff(
                "main",
                self.run_context["clone_agent_branch"],
            )

            self.logger.info(f"git diff ì¶”ì¶œ ì™„ë£Œ (ê¸¸ì´: {len(diff_result)} bytes)")
            return diff_result

        except Exception as e:
            self.logger.error(f"git diff ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            raise

    def _perform_llm_review(self, diff_content: str) -> Dict[str, Any]:
        """
        LLMì„ ì‚¬ìš©í•œ ì½”ë“œ ë¦¬ë·° ìˆ˜í–‰

        Args:
            diff_content: git diff ê²°ê³¼

        Returns:
            {
                "overall_assessment": str,
                "issues": List[Dict],
                "issue_count": Dict,
                "positive_aspects": List[str],
            }
        """
        llm_client = self.run_context.get("llm_client")

        if not llm_client:
            self.logger.warning("LLM í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ì–´ ë¦¬ë·°ë¥¼ ìŠ¤í‚µí•©ë‹ˆë‹¤")
            return {
                "overall_assessment": "APPROVE",
                "issues": [],
                "issue_count": {"critical": 0, "high": 0, "medium": 0, "low": 0},
                "positive_aspects": ["LLM ë¹„í™œì„±í™” ìƒíƒœ"],
            }

        # LLM ë¦¬ë·° í”„ë¡¬í”„íŠ¸
        prompt = f"""You are a code reviewer. Analyze the following git diff and provide a structured review.

Return your response in valid JSON format with this exact structure:
{{
  "overall_assessment": "APPROVE or REQUEST_CHANGES or COMMENT",
  "issues": [
    {{
      "severity": "CRITICAL or HIGH or MEDIUM or LOW",
      "category": "security or quality or bug or style",
      "file": "filename",
      "line": line_number_or_null,
      "description": "brief description",
      "recommendation": "how to fix"
    }}
  ],
  "positive_aspects": ["positive aspect 1", "positive aspect 2"]
}}

Review criteria:
1. Security vulnerabilities (CRITICAL/HIGH)
2. Potential bugs (HIGH/MEDIUM)
3. Code quality issues (MEDIUM/LOW)
4. Best practice violations (LOW)

Git diff:
{diff_content}
"""

        try:
            # LLM í˜¸ì¶œ
            response = llm_client.client.chat.completions.create(
                model=llm_client.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert code reviewer. Always respond with valid JSON only.",
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.3,
                max_tokens=2000,
            )

            review_text = response.choices[0].message.content.strip()

            # JSON íŒŒì‹±
            review_data = self._parse_llm_response(review_text)

            # ì˜ì–´ ì‘ë‹µì„ í•œêµ­ì–´ë¡œ ë²ˆì—­
            review_data = self._translate_review_to_korean(review_data)

            # ì‹¬ê°ë„ë³„ ì¹´ìš´íŠ¸
            issue_count = {"critical": 0, "high": 0, "medium": 0, "low": 0}
            for issue in review_data.get("issues", []):
                severity = issue.get("severity", "LOW").lower()
                if severity in issue_count:
                    issue_count[severity] += 1

            review_data["issue_count"] = issue_count

            self.logger.info(
                f"LLM ë¦¬ë·° ì™„ë£Œ: {review_data['overall_assessment']}, "
                f"ì´ìŠˆ {sum(issue_count.values())}ê°œ ë°œê²¬"
            )

            return review_data

        except Exception as e:
            self.logger.error(f"LLM ë¦¬ë·° ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ìë™ ìŠ¹ì¸
            return {
                "overall_assessment": "APPROVE",
                "issues": [],
                "issue_count": {"critical": 0, "high": 0, "medium": 0, "low": 0},
                "positive_aspects": [f"LLM ë¦¬ë·° ì‹¤íŒ¨ (ì—ëŸ¬: {str(e)})"],
            }

    def _translate_review_to_korean(self, review_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        LLM ë¦¬ë·° ê²°ê³¼ì˜ ì˜ì–´ ì„¤ëª…/ì œì•ˆì„ í•œêµ­ì–´ë¡œ ë²ˆì—­

        Args:
            review_data: LLM ë¦¬ë·° ê²°ê³¼

        Returns:
            í•œêµ­ì–´ë¡œ ë²ˆì—­ëœ ë¦¬ë·° ë°ì´í„°
        """
        llm_client = self.run_context.get("llm_client")

        if not llm_client:
            return review_data

        try:
            # ë²ˆì—­í•  í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            texts_to_translate = []
            for issue in review_data.get("issues", []):
                if issue.get("description"):
                    texts_to_translate.append(issue["description"])
                if issue.get("recommendation"):
                    texts_to_translate.append(issue["recommendation"])

            for i, aspect in enumerate(review_data.get("positive_aspects", [])):
                if isinstance(aspect, str):
                    texts_to_translate.append(aspect)

            if not texts_to_translate:
                return review_data

            # ë²ˆì—­ ìš”ì²­
            translation_prompt = f"""Translate the following English texts to Korean. Keep the format simple and concise.
Return only the Korean translations in the same order, one per line.

Texts to translate:
{chr(10).join(f'{i+1}. {text}' for i, text in enumerate(texts_to_translate))}
"""

            response = llm_client.client.chat.completions.create(
                model=llm_client.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are a translator. Translate English to Korean accurately and concisely.",
                    },
                    {"role": "user", "content": translation_prompt},
                ],
                temperature=0.3,
                max_tokens=1000,
            )

            translated_texts = response.choices[0].message.content.strip().split("\n")
            # ìˆ«ì prefix ì œê±° (ì˜ˆ: "1. í•œêµ­ì–´ í…ìŠ¤íŠ¸" â†’ "í•œêµ­ì–´ í…ìŠ¤íŠ¸")
            translated_texts = [t.split(". ", 1)[1] if ". " in t else t for t in translated_texts]

            # ë²ˆì—­ëœ í…ìŠ¤íŠ¸ë¥¼ ì›ë˜ ë°ì´í„°ì— ì ìš©
            idx = 0
            for issue in review_data.get("issues", []):
                if issue.get("description") and idx < len(translated_texts):
                    issue["description"] = translated_texts[idx]
                    idx += 1
                if issue.get("recommendation") and idx < len(translated_texts):
                    issue["recommendation"] = translated_texts[idx]
                    idx += 1

            for i, _ in enumerate(review_data.get("positive_aspects", [])):
                if idx < len(translated_texts):
                    review_data["positive_aspects"][i] = translated_texts[idx]
                    idx += 1

            self.logger.debug(f"ë¦¬ë·° ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­ ì™„ë£Œ")

        except Exception as e:
            self.logger.warning(f"ë²ˆì—­ ì‹¤íŒ¨, ì˜ì–´ë¡œ ì§„í–‰: {e}")

        return review_data

    def _parse_llm_response(self, response_text: str) -> Dict[str, Any]:
        """
        LLM ì‘ë‹µ íŒŒì‹± (JSON ì¶”ì¶œ)

        Args:
            response_text: LLM ì‘ë‹µ í…ìŠ¤íŠ¸

        Returns:
            íŒŒì‹±ëœ JSON ë°ì´í„°
        """
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        cleaned = response_text.strip()
        if cleaned.startswith("```json"):
            cleaned = cleaned[7:]
        elif cleaned.startswith("```"):
            cleaned = cleaned[3:]

        if cleaned.endswith("```"):
            cleaned = cleaned[:-3]

        cleaned = cleaned.strip()

        try:
            return json.loads(cleaned)
        except json.JSONDecodeError as e:
            self.logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            self.logger.debug(f"ì‘ë‹µ í…ìŠ¤íŠ¸: {response_text}")
            # ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
            return {
                "overall_assessment": "APPROVE",
                "issues": [],
                "positive_aspects": ["JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ìë™ ìŠ¹ì¸"],
            }

    def _approval_gate(self, review_result: Dict[str, Any]) -> bool:
        """
        ìŠ¹ì¸ ê²Œì´íŠ¸: CRITICAL/HIGH ì´ìŠˆê°€ ìˆì„ ë•Œë§Œ ì‚¬ìš©ì í™•ì¸

        Args:
            review_result: LLM ë¦¬ë·° ê²°ê³¼

        Returns:
            ì‚¬ìš©ì ìŠ¹ì¸ ì—¬ë¶€
        """
        issue_count = review_result["issue_count"]
        critical_count = issue_count.get("critical", 0)
        high_count = issue_count.get("high", 0)
        total_issues = sum(issue_count.values())

        # CRITICAL ë˜ëŠ” HIGH ì´ìŠˆê°€ ì—†ìœ¼ë©´ ìë™ ìŠ¹ì¸
        if critical_count == 0 and high_count == 0:
            if total_issues == 0:
                self.logger.info("ë¦¬ë·° ì™„ë£Œ: ì´ìŠˆ ì—†ìŒ, ìë™ ìŠ¹ì¸")
            else:
                self.logger.info(f"ë¦¬ë·° ì™„ë£Œ: ì‹¬ê°í•œ ì´ìŠˆ ì—†ìŒ ({total_issues}ê°œ ê²½ë¯¸ ì´ìŠˆ), ìë™ ìŠ¹ì¸")
            return True

        # CRITICAL/HIGH ì´ìŠˆê°€ ìˆìœ¼ë©´ ì‚¬ìš©ì í™•ì¸
        return self._request_user_approval(review_result)

    def _request_user_approval(self, review_result: Dict[str, Any]) -> bool:
        """
        ì‚¬ìš©ìì—ê²Œ ìŠ¹ì¸ ìš”ì²­

        Args:
            review_result: LLM ë¦¬ë·° ê²°ê³¼

        Returns:
            ì‚¬ìš©ì ìŠ¹ì¸ ì—¬ë¶€
        """
        issue_count = review_result["issue_count"]
        issues = review_result.get("issues", [])

        print("\n" + "=" * 80)
        print("âš ï¸  ì½”ë“œ ë¦¬ë·° ê²°ê³¼: ì´ìŠˆ ë°œê²¬")
        print("=" * 80)

        # ì‹¬ê°ë„ë³„ ìš”ì•½
        print(f"\nğŸ“Š ì´ìŠˆ ìš”ì•½:")
        print(f"  CRITICAL: {issue_count.get('critical', 0)}ê°œ")
        print(f"  HIGH:     {issue_count.get('high', 0)}ê°œ")
        print(f"  MEDIUM:   {issue_count.get('medium', 0)}ê°œ")
        print(f"  LOW:      {issue_count.get('low', 0)}ê°œ")

        # CRITICAL/HIGH ì´ìŠˆë§Œ í‘œì‹œ
        critical_high_issues = [
            issue
            for issue in issues
            if issue.get("severity", "").upper() in ["CRITICAL", "HIGH"]
        ]

        if critical_high_issues:
            print(f"\nğŸš¨ ì£¼ìš” ì´ìŠˆ ({len(critical_high_issues)}ê°œ):")
            for idx, issue in enumerate(critical_high_issues[:5], 1):  # ìµœëŒ€ 5ê°œë§Œ
                severity = issue.get("severity", "UNKNOWN")
                file_name = issue.get("file", "unknown")
                description = issue.get("description", "")
                recommendation = issue.get("recommendation", "")

                print(f"  {idx}. [{severity}] {file_name}")
                print(f"     ì„¤ëª…: {description}")
                if recommendation:
                    print(f"     ì œì•ˆ: {recommendation}")

            if len(critical_high_issues) > 5:
                print(f"  ... ì™¸ {len(critical_high_issues) - 5}ê°œ")

        print("\n" + "=" * 80)

        # ì‚¬ìš©ì ì…ë ¥
        while True:
            response = input(
                "\nê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y: ì§„í–‰, n: ì¤‘ë‹¨, d: ìƒì„¸ë³´ê¸°): "
            ).lower()

            if response == "y":
                print("âœ“ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
                return True
            elif response == "n":
                print("âœ— íŒŒì´í”„ë¼ì¸ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return False
            elif response == "d":
                self._show_detailed_review(review_result)
            else:
                print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. y, n, d ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    def _show_detailed_review(self, review_result: Dict[str, Any]) -> None:
        """
        ìƒì„¸ ë¦¬ë·° ê²°ê³¼ í‘œì‹œ

        Args:
            review_result: LLM ë¦¬ë·° ê²°ê³¼
        """
        print("\n" + "=" * 80)
        print("ğŸ“‹ ìƒì„¸ ì½”ë“œ ë¦¬ë·° ê²°ê³¼")
        print("=" * 80)

        # Overall Assessment
        assessment = review_result.get("overall_assessment", "UNKNOWN")
        print(f"\nâœ“ ì „ì²´ í‰ê°€: {assessment}")

        # Positive Aspects
        positive = review_result.get("positive_aspects", [])
        if positive:
            print(f"\nâœ… ê¸ì •ì  ì¸¡ë©´:")
            for aspect in positive:
                print(f"  - {aspect}")

        # Issues
        issues = review_result.get("issues", [])
        if issues:
            print(f"\nâš ï¸  ë°œê²¬ëœ ì´ìŠˆ ({len(issues)}ê°œ):")

            # ì‹¬ê°ë„ë³„ë¡œ ì •ë ¬
            severity_order = {"CRITICAL": 0, "HIGH": 1, "MEDIUM": 2, "LOW": 3}
            sorted_issues = sorted(
                issues,
                key=lambda x: severity_order.get(x.get("severity", "LOW").upper(), 4),
            )

            for idx, issue in enumerate(sorted_issues, 1):
                severity = issue.get("severity", "UNKNOWN")
                category = issue.get("category", "unknown")
                file_name = issue.get("file", "unknown")
                line = issue.get("line")
                description = issue.get("description", "")
                recommendation = issue.get("recommendation", "")

                print(f"\n  [{idx}] {severity} - {category}")
                print(f"      íŒŒì¼: {file_name}" + (f":{line}" if line else ""))
                print(f"      ì„¤ëª…: {description}")
                if recommendation:
                    print(f"      ì œì•ˆ: {recommendation}")

        print("\n" + "=" * 80)
